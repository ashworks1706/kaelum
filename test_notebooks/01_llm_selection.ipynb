{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219e3b80",
   "metadata": {},
   "source": [
    "# ü§ñ LLM Selection Testing\n",
    "\n",
    "**Goal:** Choose the best open-source LLM for KaelumAI project\n",
    "\n",
    "## üìä Decision Matrix (from README)\n",
    "\n",
    "| Model | Size | Speed | Quality | Use Case |\n",
    "|-------|------|-------|---------|----------|\n",
    "| **Qwen 2.5 7B** | 4.7GB | ‚ö°‚ö° Medium | ‚≠ê‚≠ê‚≠ê‚≠ê Best | Production, complex reasoning |\n",
    "| **Llama 3.2 3B** | 2.0GB | ‚ö°‚ö°‚ö° Fast | ‚≠ê‚≠ê‚≠ê Good | Dev/testing, simple tasks |\n",
    "| **Mistral 7B** | 4.1GB | ‚ö°‚ö° Medium | ‚≠ê‚≠ê‚≠ê‚≠ê Best | Code generation, structured output |\n",
    "| **Phi-3 Mini** | 2.3GB | ‚ö°‚ö°‚ö° Fast | ‚≠ê‚≠ê Okay | Edge deployment, low resource |\n",
    "\n",
    "## üéØ What We're Testing:\n",
    "1. **Speed** - Latency for simple queries\n",
    "2. **Reasoning Quality** - Logical consistency\n",
    "3. **Math Accuracy** - Calculation correctness\n",
    "4. **Reflection Rate** - How often it triggers self-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a23231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaelum import enhance\n",
    "import time\n",
    "\n",
    "# Models to test (make sure these are pulled in Ollama)\n",
    "MODELS = [\n",
    "    \"llama3.2:3b\",\n",
    "    \"qwen2.5:7b\",\n",
    "    # \"mistral:7b\",  # Uncomment if you have this\n",
    "]\n",
    "\n",
    "TEST_CONFIG = {\"temperature\": 0.3, \"max_tokens\": 512, \"max_iterations\": 1}\n",
    "print(f\"‚úÖ Testing models: {MODELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ecc2ba",
   "metadata": {},
   "source": [
    "## Test 1: Speed Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 15% of 200?\"\n",
    "results = {}\n",
    "\n",
    "for model in MODELS:\n",
    "    print(f\"\\n{'='*60}\\nTesting: {model}\\n{'='*60}\")\n",
    "    start = time.time()\n",
    "    result = enhance(query, model=model, **TEST_CONFIG)\n",
    "    elapsed = time.time() - start\n",
    "    results[model] = {\"time\": elapsed, \"result\": result}\n",
    "    print(result)\n",
    "    print(f\"\\n‚è±Ô∏è  {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"\\n{'='*60}\\nSPEED SUMMARY\\n{'='*60}\")\n",
    "for model, data in sorted(results.items(), key=lambda x: x[1]['time']):\n",
    "    print(f\"{model:20s} ‚Üí {data['time']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521deb2",
   "metadata": {},
   "source": [
    "**üìù Speed Winner:** (write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c378f1d",
   "metadata": {},
   "source": [
    "## Test 2: Reasoning Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"If all birds can fly, and penguins are birds, can penguins fly?\"\n",
    "\n",
    "for model in MODELS:\n",
    "    print(f\"\\n{'='*60}\\n{model}\\n{'='*60}\")\n",
    "    print(enhance(query, mode=\"logic\", model=model, **TEST_CONFIG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b1586",
   "metadata": {},
   "source": [
    "**üìù Best reasoning:** (write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3cd0f",
   "metadata": {},
   "source": [
    "## Test 3: Math Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"Solve: 3x + 5 = 20\", \"What is sqrt(144)?\", \"Calculate: (15 √ó 8) √∑ 4\"]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*60}\\n{query}\\n{'='*60}\")\n",
    "    for model in MODELS:\n",
    "        print(f\"\\n{model}:\")\n",
    "        print(enhance(query, mode=\"math\", model=model, **TEST_CONFIG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2a1aa",
   "metadata": {},
   "source": [
    "**üìù Math accuracy winner:** (write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd61265",
   "metadata": {},
   "source": [
    "## üéØ Final Decision\n",
    "\n",
    "### Recommended:\n",
    "- **For Development:**\n",
    "- **For Production:**\n",
    "- **Reasoning:**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
