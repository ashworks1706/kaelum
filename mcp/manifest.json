{
  "name": "kaelum-reasoning",
  "version": "0.1.0",
  "description": "The All-in-One Reasoning Layer for Agentic LLMs",
  "protocol_version": "0.1",
  "capabilities": {
    "reasoning": {
      "generation": true,
      "verification": true,
      "reflection": true,
      "confidence_scoring": true
    },
    "verification_methods": [
      "symbolic",
      "factual_rag",
      "multi_llm"
    ],
    "supported_llms": [
      "openai",
      "anthropic"
    ]
  },
  "endpoints": [
    {
      "path": "/verify_reasoning",
      "method": "POST",
      "description": "Verify and improve reasoning traces"
    },
    {
      "path": "/metrics",
      "method": "GET",
      "description": "Get reasoning quality metrics"
    }
  ],
  "configuration": {
    "llm": {
      "model": "gpt-4o-mini",
      "temperature": 0.7,
      "max_tokens": 2048
    },
    "verification": {
      "use_symbolic": true,
      "use_rag": false,
      "confidence_threshold": 0.7,
      "max_reflection_iterations": 2
    },
    "policy": {
      "enable_adaptive_controller": true,
      "enable_trace_logging": true
    }
  },
  "integration": {
    "langchain": {
      "tool_name": "kaelum_reasoning",
      "compatible": true
    },
    "langgraph": {
      "node_type": "reasoning_verification",
      "compatible": true
    }
  }
}
